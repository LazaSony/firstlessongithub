{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "Attribute Information\n1) age\n2) sex\n3) chest pain type (4 values)\n4) resting blood pressure\n5) serum cholestoral in mg/dl\n6) fasting blood sugar > 120 mg/dl\n7) resting electrocardiographic results (values 0,1,2)\n8) maximum heart rate achieved\n9) exercise induced angina\n10) oldpeak = ST depression induced by exercise relative to rest\n11) the slope of the peak exercise ST segment\n12) number of major vessels (0-3) colored by flourosopy\n13) thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n14) target: 0= less chance of heart attack 1= more chance of heart attack\n\n`target` refers to the presence of heart disease in the patient. It is integer valued 0 = no/less chance of heart attack and 1 = more chance of heart attack.\n\nCreate a classification model, by using optuna to find the best model/parameters, and after that create a class with the best model Optuna found during hyper-parameter optimization process. Make sure this class includes all the pre-processing steps (if any) that Optuna used. Make sure that this class has a `get_prediction()` function, that can be called (by the front-end user interface for example), with the parameters, and it returns the prdiction of the target.",
   "metadata": {
    "tags": [],
    "cell_id": "00000-f51dd5a0-dd0e-4420-846b-389289f4adba",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-89b06d2f-805b-4640-9b5c-4cbd9d50fa9d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a82c062",
    "execution_start": 1633970155551,
    "execution_millis": 3982,
    "deepnote_cell_type": "code"
   },
   "source": "!pip install optuna",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: optuna in /root/venv/lib/python3.7/site-packages (2.10.0)\nRequirement already satisfied: cliff in /root/venv/lib/python3.7/site-packages (from optuna) (3.9.0)\nRequirement already satisfied: tqdm in /shared-libs/python3.7/py/lib/python3.7/site-packages (from optuna) (4.62.3)\nRequirement already satisfied: colorlog in /root/venv/lib/python3.7/site-packages (from optuna) (6.5.0)\nRequirement already satisfied: PyYAML in /shared-libs/python3.7/py/lib/python3.7/site-packages (from optuna) (5.4.1)\nRequirement already satisfied: alembic in /root/venv/lib/python3.7/site-packages (from optuna) (1.7.4)\nRequirement already satisfied: cmaes>=0.8.2 in /root/venv/lib/python3.7/site-packages (from optuna) (0.8.2)\nRequirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from optuna) (1.19.5)\nRequirement already satisfied: scipy!=1.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from optuna) (1.7.1)\nRequirement already satisfied: sqlalchemy>=1.1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from optuna) (1.4.25)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from optuna) (21.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging>=20.0->optuna) (2.4.7)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from sqlalchemy>=1.1.0->optuna) (4.8.1)\nRequirement already satisfied: greenlet!=0.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\nRequirement already satisfied: importlib-resources in /root/venv/lib/python3.7/site-packages (from alembic->optuna) (5.2.2)\nRequirement already satisfied: Mako in /root/venv/lib/python3.7/site-packages (from alembic->optuna) (1.1.5)\nRequirement already satisfied: pbr!=2.1.0,>=2.0.0 in /root/venv/lib/python3.7/site-packages (from cliff->optuna) (5.6.0)\nRequirement already satisfied: stevedore>=2.0.1 in /root/venv/lib/python3.7/site-packages (from cliff->optuna) (3.4.0)\nRequirement already satisfied: PrettyTable>=0.7.2 in /root/venv/lib/python3.7/site-packages (from cliff->optuna) (2.2.1)\nRequirement already satisfied: autopage>=0.4.0 in /root/venv/lib/python3.7/site-packages (from cliff->optuna) (0.4.0)\nRequirement already satisfied: cmd2>=1.0.0 in /root/venv/lib/python3.7/site-packages (from cliff->optuna) (2.2.0)\nRequirement already satisfied: wcwidth>=0.1.7 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\nRequirement already satisfied: attrs>=16.3.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\nRequirement already satisfied: colorama>=0.3.7 in /root/venv/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\nRequirement already satisfied: pyperclip>=1.6 in /root/venv/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from Mako->alembic->optuna) (2.0.1)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-2a10cb08-5f39-473a-9e59-21bacda7f4c9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9e2bbd8f",
    "execution_start": 1633970178137,
    "execution_millis": 3118,
    "deepnote_cell_type": "code"
   },
   "source": "import optuna\nimport pandas as pd\n\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport sklearn.datasets\nimport sklearn.ensemble\nimport sklearn.model_selection\nimport sklearn.svm\nfrom sklearn import tree\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, StandardScaler, PowerTransformer,Normalizer\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\nfrom sklearn.model_selection import cross_val_score\n\npath = \"/work/data/homework 26/heart.csv\"\n\ndf = pd.read_csv(path)\ndf.head()\ndf.info()",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 303 entries, 0 to 302\nData columns (total 14 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       303 non-null    int64  \n 1   sex       303 non-null    int64  \n 2   cp        303 non-null    int64  \n 3   trestbps  303 non-null    int64  \n 4   chol      303 non-null    int64  \n 5   fbs       303 non-null    int64  \n 6   restecg   303 non-null    int64  \n 7   thalach   303 non-null    int64  \n 8   exang     303 non-null    int64  \n 9   oldpeak   303 non-null    float64\n 10  slope     303 non-null    int64  \n 11  ca        303 non-null    int64  \n 12  thal      303 non-null    int64  \n 13  target    303 non-null    int64  \ndtypes: float64(1), int64(13)\nmemory usage: 33.3 KB\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-53705524-94fd-444a-93f7-90e20b74d8f0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1d8f6039",
    "execution_start": 1633806969973,
    "execution_millis": 19983,
    "deepnote_cell_type": "code"
   },
   "source": "def load_data():\n    \n    df=pd.read_csv(path)\n    X=df.drop([\"target\"],axis = 1)\n    y=df[\"target\"]\n    return X,y\n\ndef objective(trial):\n\n    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVC\", \"RandomForest\",\"DecisionTreeClassifier\",\"AdaBoostClassifier\"])\n    if classifier_name == \"SVC\":\n        svc_c = trial.suggest_float(\"svc_c\", 1e-5, 1e5, log=True)\n        model = sklearn.svm.SVC(C=svc_c, gamma=\"auto\")\n    elif classifier_name == \"RandomForest\":\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 12, log=True)\n        model = sklearn.ensemble.RandomForestClassifier(max_depth=rf_max_depth, \n                                                        n_estimators=10)\n    elif classifier_name == \"DecisionTreeClassifier\":\n        dt_criteria = trial.suggest_categorical(\"dt_criteria\",[\"gini\",\"entropy\"])\n        dt_max_depth = trial.suggest_int(\"dt_max_depth\", 2, 12)\n        model = tree.DecisionTreeClassifier(criterion= dt_criteria,\n                                            max_depth=dt_max_depth)\n    elif classifier_name == 'AdaBoostClassifier':\n        learning_rate = trial.suggest_uniform('learning_rate', 1e-3, 1) # 1e-10, 1e10\n        sug_ada_estims = trial.suggest_int(\"estimators\", 2, 32)\n        model = AdaBoostClassifier(n_estimators=sug_ada_estims,learning_rate=learning_rate)  \n  \n                                          \n    scaler_string = trial.suggest_categorical(\"------------------------------------_scaler\",[\"no_scaler\", \"StandardScaler\",\"RobustScaler\",\"MinMaxScaler\", \"MaxAbsScaler\", \"StandardScaler\", \"PowerTransformer\",\"Normalizer\"])\n    \n    if scaler_string == \"no_scaler\":\n        scaled_X = X\n    else:\n        scaler = eval(scaler_string)()\n        scaler.fit(X)\n        scaled_X = scaler.transform(X)\n\n\n    #cv_string = trial.suggest_categorical(\"validator\",[\"StratifiedKFold\",\"KFold\"])\n    #if cv_string == \"StratifiedKFold\":\n        #cv_string_model= StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n    #elif cv_string == \"KFold\":\n        # cv_string_model= KFold(n_splits=5,shuffle=True,random_state=42)\n\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    score = cross_val_score(model, scaled_X, y, cv=cv,scoring=\"f1_weighted\")\n    trial_score = score.mean()\n\n    return trial_score\n\nX, y = load_data()\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=100)\nprint(study.best_trial)\n\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "\u001b[32m[I 2021-10-09 19:16:09,938]\u001b[0m A new study created in memory with name: no-name-3f45d014-1334-4f15-bd04-4f58230c8137\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:09,973]\u001b[0m Trial 0 finished with value: 0.8040695064824256 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'entropy', 'dt_max_depth': 3, '------------------------------------_scaler': 'RobustScaler'}. Best is trial 0 with value: 0.8040695064824256.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:10,025]\u001b[0m Trial 1 finished with value: 0.7923026574461376 and parameters: {'classifier': 'SVC', 'svc_c': 0.06436649351644572, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 0 with value: 0.8040695064824256.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:10,133]\u001b[0m Trial 2 finished with value: 0.7967720537548736 and parameters: {'classifier': 'SVC', 'svc_c': 41510.02520093985, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 0 with value: 0.8040695064824256.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:10,274]\u001b[0m Trial 3 finished with value: 0.8131608729141353 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 3, '------------------------------------_scaler': 'MaxAbsScaler'}. Best is trial 3 with value: 0.8131608729141353.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:10,329]\u001b[0m Trial 4 finished with value: 0.7960570302665185 and parameters: {'classifier': 'SVC', 'svc_c': 1.3979866513803878, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 3 with value: 0.8131608729141353.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:10,377]\u001b[0m Trial 5 finished with value: 0.7806069229337632 and parameters: {'classifier': 'SVC', 'svc_c': 8.769725469631759, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 3 with value: 0.8131608729141353.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:10,441]\u001b[0m Trial 6 finished with value: 0.7611438278698551 and parameters: {'classifier': 'SVC', 'svc_c': 1611.176241082574, '------------------------------------_scaler': 'RobustScaler'}. Best is trial 3 with value: 0.8131608729141353.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:10,635]\u001b[0m Trial 7 finished with value: 0.8365000365597235 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 5, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:10,828]\u001b[0m Trial 8 finished with value: 0.8361656764089078 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.5604264105210585, 'estimators': 11, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:10,877]\u001b[0m Trial 9 finished with value: 0.7535353978612644 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'entropy', 'dt_max_depth': 6, '------------------------------------_scaler': 'no_scaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:11,055]\u001b[0m Trial 10 finished with value: 0.7943318417549098 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, '------------------------------------_scaler': 'MinMaxScaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:11,260]\u001b[0m Trial 11 finished with value: 0.8327406517838899 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.5709646541505616, 'estimators': 11, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:11,472]\u001b[0m Trial 12 finished with value: 0.815865230592863 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.13236502933957833, 'estimators': 12, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:11,865]\u001b[0m Trial 13 finished with value: 0.7976061225505379 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.9750228806399175, 'estimators': 32, '------------------------------------_scaler': 'Normalizer'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:12,006]\u001b[0m Trial 14 finished with value: 0.8229793979456126 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:12,073]\u001b[0m Trial 15 finished with value: 0.8265922687052747 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.5668405285808373, 'estimators': 3, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:12,257]\u001b[0m Trial 16 finished with value: 0.8285994780870389 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 2, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:12,552]\u001b[0m Trial 17 finished with value: 0.8326763507583493 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.22080981506244407, 'estimators': 22, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:12,697]\u001b[0m Trial 18 finished with value: 0.816941402098184 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:12,731]\u001b[0m Trial 19 finished with value: 0.7371249630497515 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'gini', 'dt_max_depth': 12, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:12,787]\u001b[0m Trial 20 finished with value: 0.7230508336989226 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.8528120879367267, 'estimators': 2, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:13,014]\u001b[0m Trial 21 finished with value: 0.8327706939566918 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.55423178967767, 'estimators': 13, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 7 with value: 0.8365000365597235.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:13,217]\u001b[0m Trial 22 finished with value: 0.8428934588869778 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.40994309354678804, 'estimators': 17, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 22 with value: 0.8428934588869778.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:13,460]\u001b[0m Trial 23 finished with value: 0.846427111644458 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.350550223221607, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 23 with value: 0.846427111644458.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:13,610]\u001b[0m Trial 24 finished with value: 0.8273399440449927 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 4, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 23 with value: 0.846427111644458.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:13,893]\u001b[0m Trial 25 finished with value: 0.8368853110029997 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.293752591219609, 'estimators': 24, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 23 with value: 0.846427111644458.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:14,162]\u001b[0m Trial 26 finished with value: 0.8336869551203654 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3243663614202397, 'estimators': 23, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 23 with value: 0.846427111644458.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:14,412]\u001b[0m Trial 27 finished with value: 0.8527778227912446 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.33969753014326165, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:14,641]\u001b[0m Trial 28 finished with value: 0.8427657772470237 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3774877289271146, 'estimators': 17, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:14,678]\u001b[0m Trial 29 finished with value: 0.7418696021678932 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'gini', 'dt_max_depth': 12, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:14,922]\u001b[0m Trial 30 finished with value: 0.7279623983745953 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.0060113362524347735, 'estimators': 19, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:15,164]\u001b[0m Trial 31 finished with value: 0.8392337278075296 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.4046967445135615, 'estimators': 17, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:15,375]\u001b[0m Trial 32 finished with value: 0.8395880781898672 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.4175843727748086, 'estimators': 18, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:15,695]\u001b[0m Trial 33 finished with value: 0.8292863018814873 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.4195161686748675, 'estimators': 27, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:15,889]\u001b[0m Trial 34 finished with value: 0.8200461034182723 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.22307456736594955, 'estimators': 16, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:16,132]\u001b[0m Trial 35 finished with value: 0.8263003150514617 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.6973443768338676, 'estimators': 20, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:16,443]\u001b[0m Trial 36 finished with value: 0.8392560422392886 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3826114936262357, 'estimators': 25, '------------------------------------_scaler': 'MaxAbsScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:16,513]\u001b[0m Trial 37 finished with value: 0.3840327643822362 and parameters: {'classifier': 'SVC', 'svc_c': 0.0003658262034621004, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:16,548]\u001b[0m Trial 38 finished with value: 0.7018929279381698 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'entropy', 'dt_max_depth': 2, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:16,742]\u001b[0m Trial 39 finished with value: 0.825839191184517 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.26158309894571813, 'estimators': 15, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:16,797]\u001b[0m Trial 40 finished with value: 0.3840327643822362 and parameters: {'classifier': 'SVC', 'svc_c': 1.858971508309421e-05, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:17,036]\u001b[0m Trial 41 finished with value: 0.8269029093288014 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.4570658943383984, 'estimators': 19, '------------------------------------_scaler': 'RobustScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:17,274]\u001b[0m Trial 42 finished with value: 0.8397141419923793 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.355427989631404, 'estimators': 20, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:17,530]\u001b[0m Trial 43 finished with value: 0.8527778227912446 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.33545456618386954, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:17,798]\u001b[0m Trial 44 finished with value: 0.8395047073439319 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3122790580668535, 'estimators': 22, '------------------------------------_scaler': 'MinMaxScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:17,986]\u001b[0m Trial 45 finished with value: 0.815994354921753 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.15620805702360524, 'estimators': 15, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:18,068]\u001b[0m Trial 46 finished with value: 0.3840327643822362 and parameters: {'classifier': 'SVC', 'svc_c': 0.008976173070830545, '------------------------------------_scaler': 'no_scaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:18,366]\u001b[0m Trial 47 finished with value: 0.8261613705435387 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.4687260687097372, 'estimators': 26, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:18,713]\u001b[0m Trial 48 finished with value: 0.8527778227912446 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.34164246429405565, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:18,758]\u001b[0m Trial 49 finished with value: 0.7410726324094654 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'gini', 'dt_max_depth': 8, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:19,082]\u001b[0m Trial 50 finished with value: 0.8256255188847831 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.17038368524717826, 'estimators': 29, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:19,329]\u001b[0m Trial 51 finished with value: 0.8431645185253613 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3121654420375116, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:19,589]\u001b[0m Trial 52 finished with value: 0.8431645185253613 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3081777675355144, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:19,857]\u001b[0m Trial 53 finished with value: 0.8392337278075296 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.2891373505505357, 'estimators': 22, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:20,107]\u001b[0m Trial 54 finished with value: 0.8292125170643366 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.223809411357846, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:20,412]\u001b[0m Trial 55 finished with value: 0.8259514471612448 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.5237958302029677, 'estimators': 24, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:20,669]\u001b[0m Trial 56 finished with value: 0.8427673805650098 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3568033395021015, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:20,814]\u001b[0m Trial 57 finished with value: 0.8006738016234841 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:21,117]\u001b[0m Trial 58 finished with value: 0.8261430754009643 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.260358018503246, 'estimators': 20, '------------------------------------_scaler': 'Normalizer'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:21,175]\u001b[0m Trial 59 finished with value: 0.7674292795559601 and parameters: {'classifier': 'SVC', 'svc_c': 104.76887183508113, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:21,439]\u001b[0m Trial 60 finished with value: 0.8091895291172729 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.09027905974661032, 'estimators': 23, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:21,664]\u001b[0m Trial 61 finished with value: 0.833460366479963 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.32785715895776296, 'estimators': 18, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:21,760]\u001b[0m Trial 62 finished with value: 0.8130531009597293 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.46704551319867305, 'estimators': 6, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:22,020]\u001b[0m Trial 63 finished with value: 0.8366639984944146 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3512315975987107, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:22,244]\u001b[0m Trial 64 finished with value: 0.8227216597580325 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.6573769556795779, 'estimators': 19, '------------------------------------_scaler': 'MaxAbsScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:22,426]\u001b[0m Trial 65 finished with value: 0.8327179541267904 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.42975292424134004, 'estimators': 13, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:22,464]\u001b[0m Trial 66 finished with value: 0.745183493360125 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'entropy', 'dt_max_depth': 8, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:22,759]\u001b[0m Trial 67 finished with value: 0.8401463809060916 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.26649967662470003, 'estimators': 24, '------------------------------------_scaler': 'RobustScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:22,898]\u001b[0m Trial 68 finished with value: 0.7734125816147888 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 2, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:23,166]\u001b[0m Trial 69 finished with value: 0.8293784912455069 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.1913029329904601, 'estimators': 23, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n\u001b[32m[I 2021-10-09 19:16:23,522]\u001b[0m Trial 70 finished with value: 0.8259514471612448 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.5054482758197205, 'estimators': 28, '------------------------------------_scaler': 'no_scaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:23,774]\u001b[0m Trial 71 finished with value: 0.8527778227912446 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3445421284086182, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:24,043]\u001b[0m Trial 72 finished with value: 0.8462540796670748 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3256837099709864, 'estimators': 22, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:24,320]\u001b[0m Trial 73 finished with value: 0.8395047073439319 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3140242838099208, 'estimators': 22, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:24,577]\u001b[0m Trial 74 finished with value: 0.8354413964701747 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.2528604309247638, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:24,862]\u001b[0m Trial 75 finished with value: 0.8426810668643065 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3675535453294713, 'estimators': 25, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:25,141]\u001b[0m Trial 76 finished with value: 0.8359727380064191 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.2864440646368298, 'estimators': 19, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:25,416]\u001b[0m Trial 77 finished with value: 0.8364530720892874 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3220172969600948, 'estimators': 23, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:25,644]\u001b[0m Trial 78 finished with value: 0.8496794921942665 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3998248418400425, 'estimators': 18, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:25,702]\u001b[0m Trial 79 finished with value: 0.7674292795559601 and parameters: {'classifier': 'SVC', 'svc_c': 55394.60136560061, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:25,739]\u001b[0m Trial 80 finished with value: 0.7414487512317868 and parameters: {'classifier': 'DecisionTreeClassifier', 'dt_criteria': 'gini', 'dt_max_depth': 5, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:25,974]\u001b[0m Trial 81 finished with value: 0.8429616746324591 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3835617186438459, 'estimators': 18, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:26,222]\u001b[0m Trial 82 finished with value: 0.8402534057205677 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3374382184200316, 'estimators': 20, '------------------------------------_scaler': 'MinMaxScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:26,510]\u001b[0m Trial 83 finished with value: 0.8329474038508273 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.42107336277978025, 'estimators': 22, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:26,757]\u001b[0m Trial 84 finished with value: 0.8495167528881528 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.38384344897673967, 'estimators': 20, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:26,973]\u001b[0m Trial 85 finished with value: 0.8327116681033273 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.4540954978619888, 'estimators': 17, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:27,219]\u001b[0m Trial 86 finished with value: 0.826010194171463 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3712015326304236, 'estimators': 19, '------------------------------------_scaler': 'Normalizer'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:27,412]\u001b[0m Trial 87 finished with value: 0.8474583935190347 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:27,557]\u001b[0m Trial 88 finished with value: 0.7672903653863148 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:27,689]\u001b[0m Trial 89 finished with value: 0.8211278251843643 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:27,819]\u001b[0m Trial 90 finished with value: 0.8394821431524688 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 3, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:27,954]\u001b[0m Trial 91 finished with value: 0.8242151198410813 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:28,225]\u001b[0m Trial 92 finished with value: 0.8262815833508614 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.3950734908017168, 'estimators': 16, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:28,427]\u001b[0m Trial 93 finished with value: 0.8063252166897674 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 4, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n  loglike = -n_samples / 2 * np.log(x_trans.var())\n\u001b[32m[I 2021-10-09 19:16:28,804]\u001b[0m Trial 94 finished with value: 0.8297439413950725 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.9093886012690291, 'estimators': 20, '------------------------------------_scaler': 'PowerTransformer'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:29,152]\u001b[0m Trial 95 finished with value: 0.8361333975191764 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.23565637369195136, 'estimators': 24, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:29,366]\u001b[0m Trial 96 finished with value: 0.8361686353918545 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.43744872338119345, 'estimators': 18, '------------------------------------_scaler': 'MaxAbsScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:29,642]\u001b[0m Trial 97 finished with value: 0.8394603965499131 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.39899673718579404, 'estimators': 22, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:29,880]\u001b[0m Trial 98 finished with value: 0.8460284504681017 and parameters: {'classifier': 'AdaBoostClassifier', 'learning_rate': 0.2897464205572264, 'estimators': 20, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\n\u001b[32m[I 2021-10-09 19:16:29,941]\u001b[0m Trial 99 finished with value: 0.3840327643822362 and parameters: {'classifier': 'SVC', 'svc_c': 1.2115295851895381e-05, '------------------------------------_scaler': 'StandardScaler'}. Best is trial 27 with value: 0.8527778227912446.\u001b[0m\nFrozenTrial(number=27, values=[0.8527778227912446], datetime_start=datetime.datetime(2021, 10, 9, 19, 16, 14, 163605), datetime_complete=datetime.datetime(2021, 10, 9, 19, 16, 14, 411338), params={'classifier': 'AdaBoostClassifier', 'learning_rate': 0.33969753014326165, 'estimators': 21, '------------------------------------_scaler': 'StandardScaler'}, distributions={'classifier': CategoricalDistribution(choices=('SVC', 'RandomForest', 'DecisionTreeClassifier', 'AdaBoostClassifier')), 'learning_rate': UniformDistribution(high=1.0, low=0.001), 'estimators': IntUniformDistribution(high=32, low=2, step=1), '------------------------------------_scaler': CategoricalDistribution(choices=('no_scaler', 'StandardScaler', 'RobustScaler', 'MinMaxScaler', 'MaxAbsScaler', 'StandardScaler', 'PowerTransformer', 'Normalizer'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=27, state=TrialState.COMPLETE, value=None)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-b1b40ade-b5ea-4659-961d-a31e5fbab9a0",
    "deepnote_cell_type": "code"
   },
   "source": "'classifier': 'AdaBoostClassifier', \n'learning_rate': 0.2501994775312749,'estimators': 26, \n'------------------------------------_scaler': 'no_scaler'\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-af3b3ac2-ee78-44f7-a582-97e8fab93906",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c8ea70f8",
    "execution_start": 1633971584762,
    "execution_millis": 194,
    "deepnote_cell_type": "code"
   },
   "source": "import optuna\nimport pandas as pd\n\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport sklearn.datasets\nimport sklearn.ensemble\nimport sklearn.model_selection\nimport sklearn.svm\nfrom sklearn import tree\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, StandardScaler, PowerTransformer,Normalizer\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\nfrom sklearn.model_selection import cross_val_score\nimport pickle\npath = \"/work/data/homework 26/heart.csv\"\n\n\nclass PredictHeartProblems():\n    MODEL_SAVE_LOCATION = \"/work/data/homework 26/classification_model.joblib\"\n\n    def __init__(self, path):\n        self.df = self.load_model(path)\n        self.X, self.y = self.preprocessing()\n        self.train_best_model()\n        self.save_model()\n        \n    def load_model(self, path):\n        return pd.read_csv(path)\n\n    def preprocessing(self):\n        X = df.drop([\"target\"],axis = 1)\n        y = df[\"target\"]\n        return X,y\n\n    def train_best_model(self):\n        self.model = AdaBoostClassifier(n_estimators=26,learning_rate=0.2501994775312749)\n        self.model.fit(self.X, self.y)\n        # we now test if everything works until this point\n        # self.test = self.model.predict(self.X)\n    \n    def save_model(self):\n        pickle.dump(self.model,  open(self.MODEL_SAVE_LOCATION, 'wb'))\n\n    def predict(self, value_to_predict):\n        loaded_model = pickle.load(open(self.MODEL_SAVE_LOCATION, 'rb'))\n\n        df= pd.DataFrame([value_to_predict],columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'])\n\n        prediction = self.model.predict(df)[0]\n        list_of_prediction_labels = [\"No heart problem\", \"Possible heart problem\"]\n\n        return list_of_prediction_labels[prediction]\n\n\nmodel = PredictHeartProblems(path)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-17a1ed64-3c62-4cba-a421-46b385a480dc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9e05a120",
    "execution_start": 1633971586610,
    "execution_millis": 21,
    "deepnote_cell_type": "code"
   },
   "source": "index = 200\nvalue_to_predict = list(model.X.iloc[index].values)\npredicted_class = model.predict(value_to_predict)\n\ntrue_class = model.y.iloc[index]\n\nprint(f\"Prediction is: {predicted_class}\\nTrue class is: {true_class}\")",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Prediction is: No heart problem\nTrue class is: 0\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-5b67d47b-5984-40d3-b876-29c2a8b376cc",
    "deepnote_cell_type": "code"
   },
   "source": "model.predict([44.0, 1.0, 0.0, 110.0, 197.0, 0.0, 0.0, 177.0, 0.0, 0.0, 2.0, 1.0, 2.0])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-c32f2f01-099f-4183-8aa6-cca5fecfde8e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "db8119d8",
    "execution_start": 1633806839888,
    "execution_millis": 108,
    "deepnote_cell_type": "code"
   },
   "source": "import optuna\nimport pandas as pd\n\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport sklearn.datasets\nimport sklearn.ensemble\nimport sklearn.model_selection\nimport sklearn.svm\nfrom sklearn import tree\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, StandardScaler, PowerTransformer,Normalizer\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\nfrom sklearn.model_selection import cross_val_score\n\npath = \"/work/data/homework 26/heart.csv\"\n\nclass Model:\n    def __init__(self, datafile = \"/work/data/homework 26/heart.csv\"):\n       self.df = pd.read_csv(datafile)\n       self.user_defined_model = AdaBoostClassifier(n_estimators=26,learning_rate=0.2501994775312749)\n            \n    def split(self, test_size):\n\n        X=df.drop([\"target\"],axis = 1)\n        y=df[\"target\"]\n        \n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = test_size, random_state = 42)\n    \n    def fit(self):\n        self.model = self.user_defined_model.fit(self.X_train, self.y_train)\n    \n    def predict(self, input_value):\n        if input_value == None:\n            result = self.user_defined_model.predict(self.X_test)\n        else: \n            result = self.user_defined_model.predict(np.array([input_value]))\n        return result\n\nif __name__ == '__main__':\n    model_instance = Model()\n    model_instance.split(0.3)\n    model_instance.fit()    \n    print(model_instance.predict([\"5\",\"1\",\"3\",\"145\",\"273\",\"1\",\"0\",\"150\",\"2.3\",\"0\",\"0\",\"1\",\"5\"]))\n    print(\"Accuracy: \", model_instance.model.score(model_instance.X_test, model_instance.y_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[0]\nAccuracy:  0.8461538461538461\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py:442: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  \"X does not have valid feature names, but\"\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=7d3ce7c8-a514-49e4-9ba4-a5899ac52ea5' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "9b0dd43d-204c-4af7-835d-a86a74696865",
  "deepnote_execution_queue": []
 }
}